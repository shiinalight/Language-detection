# Language-detection
using the [Language Detection dataset](https://www.kaggle.com/basilb2s/language-detection), which contains text details for 17 different languages.
About the Dataset
It's a small language detection dataset. This dataset consists of text details for 17 different languages, ie, you will be able to create an NLP model for predicting 17 different language..

Languages
1) English
2) Malayalam
3) Hindi
4) Tamil
5) Kannada
6) French
7) Spanish
8) Portuguese
9) Italian
10) Russian
11) Sweedish
12) Dutch
13) Arabic
14) Turkish
15) German
16) Danish
17) Greek

Using the text we have to create a model which will be able to predict the given language. This is a solution for many artificial intelligence applications and computational linguists. These kinds of prediction systems are widely used in electronic devices such as mobiles, laptops, etc for machine translation, and also on robots. It helps in tracking and identifying multilingual documents too. The domain of NLP is still a lively area of researchers.

# Road map

### 22.Import all the required libraries, then import the language detection dataset

### Separating Independent and Dependent features

### Label Encoding

### Text Preprocessing

### Bag of Words

### Train Test Splitting

### Model Training and Prediction

### Model Evaluation

### Predicting with some more data

# Conclusion
This project would have definitely given a diagram of basic NLP programs. We need to analyze the data and preprocess it accordingly. A bag of words model becomes a way of representing your text data. Text extraction and vectorization are important steps for good predictions in NLP. Naive Bayes always proves to be a better model in such text classification problems, hence more accurate results we get.


